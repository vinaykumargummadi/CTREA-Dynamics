{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f588ae",
   "metadata": {},
   "source": [
    "# Model Deployment Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e801c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "import time\n",
    "# Record the start time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58c3ca59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 884233 entries, 0 to 884232\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   Unnamed: 0                   884233 non-null  int64  \n",
      " 1   List Year                    884233 non-null  int64  \n",
      " 2   Assessed Value               884233 non-null  float64\n",
      " 3   Sale Amount                  884233 non-null  float64\n",
      " 4   Sales Ratio                  884233 non-null  float64\n",
      " 5   Property Type                884233 non-null  object \n",
      " 6   Street Number                884233 non-null  int64  \n",
      " 7   Minimum Estimated Occupancy  884233 non-null  int64  \n",
      " 8   County                       884233 non-null  object \n",
      " 9   Reason Category              843753 non-null  object \n",
      " 10  year                         884233 non-null  int64  \n",
      " 11  month                        884233 non-null  int64  \n",
      " 12  day                          884233 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(3)\n",
      "memory usage: 87.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\dhami\\Downloads\\GitHub_Capstone_Project\\CTREA-Dynamics\\data\\Pipeline_Dataset.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbd6f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "X = data.drop(columns=['Unnamed: 0','Sales Ratio','Sale Amount','month', 'day'], axis=1)\n",
    "y = data['Sale Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "319873c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the drop_columns function\n",
    "# def drop_columns(X):\n",
    "#     return X.drop(columns=columns_to_drop)\n",
    "\n",
    "#applying log transformation \n",
    "def apply_log_transformation(X):\n",
    "    X['Assessed Value'] = np.log1p(X['Assessed Value'])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb462c86",
   "metadata": {},
   "source": [
    "        #creating new features for data comphresion\n",
    "        def create_new_features(X):\n",
    "            X['Assessed_Sales_Ratio'] = X['Assessed Value'] * X['Sales Ratio']\n",
    "            #if you have more features and need to call same use same code\n",
    "            #keep adding new feautres logic herein \n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ef76d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_to_drop = ['month', 'day']\n",
    "categorical_features = ['Property Type', 'County', 'Reason Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b6d34ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pipeline to drop with custom transformer\n",
    "pipeline = Pipeline([\n",
    "    #('feature_engineering', FunctionTransformer(create_new_features)),\n",
    "    #step 1 : feature engineering\n",
    "    ('log_transformation', FunctionTransformer(apply_log_transformation)),\n",
    "    #step 2 : data transformation for machine learning model optimization\n",
    "    #('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    #step 3 : identify features to drop \n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers = [('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
    "        remainder = 'passthrough'\n",
    "    )),\n",
    "    #step 4 : numerical and categorical numerical encoding for numerical follow same step add line after categorical\n",
    "    # Feature selection\n",
    "    ('feature_selection', SelectKBest(f_regression, k=10)),\n",
    "    #Regression Model \n",
    "    ('XGBoost_Regressor', XGBRegressor())\n",
    "    #step 5 : Passing data through model for training and testing\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1df08e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((707386, 8), (176847, 8), (707386,), (176847,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92db7ae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;log_transformation&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function apply_log_transformation at 0x000001F530CC3130&gt;)),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;Property Type&#x27;, &#x27;County&#x27;,\n",
       "                                                   &#x27;Reason Category&#x27;])])),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 SelectKBest(score_func=&lt;function f_re...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;log_transformation&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function apply_log_transformation at 0x000001F530CC3130&gt;)),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;categorical&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;Property Type&#x27;, &#x27;County&#x27;,\n",
       "                                                   &#x27;Reason Category&#x27;])])),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 SelectKBest(score_func=&lt;function f_re...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function apply_log_transformation at 0x000001F530CC3130&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;categorical&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;Property Type&#x27;, &#x27;County&#x27;,\n",
       "                                  &#x27;Reason Category&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Property Type&#x27;, &#x27;County&#x27;, &#x27;Reason Category&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;List Year&#x27;, &#x27;Assessed Value&#x27;, &#x27;Street Number&#x27;, &#x27;Minimum Estimated Occupancy&#x27;, &#x27;year&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(score_func=&lt;function f_regression at 0x000001F5782E5EA0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('log_transformation',\n",
       "                 FunctionTransformer(func=<function apply_log_transformation at 0x000001F530CC3130>)),\n",
       "                ('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('categorical',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['Property Type', 'County',\n",
       "                                                   'Reason Category'])])),\n",
       "                ('feature_selection',\n",
       "                 SelectKBest(score_func=<function f_re...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply transformations to target for test set\n",
    "y_train_transformed = np.log1p(y_train)\n",
    "\n",
    "# Fit the entire pipeline on the training data\n",
    "pipeline.fit(X_train, y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5795776a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.09792490478322377\n",
      "Mean Absolute Error: 0.20223910664208916\n",
      "R2 Score: 0.8546805840679981\n",
      "Total execution time: 4.424556732177734 seconds\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations to target for test set\n",
    "y_test_transformed = np.log1p(y_test)\n",
    "\n",
    "# Transform the test set using the pipeline\n",
    "X_test_transformed = pipeline[:-1].transform(X_test)\n",
    "# -1 will leave XGboost not to be applied for other steps in pipline will be done!!\n",
    "\n",
    "# Make predictions on the transformed test set\n",
    "y_pred_transformed = pipeline[-1].predict(X_test_transformed)\n",
    "\n",
    "# Inverse transform predictions to get them back to the original scale\n",
    "y_pred = np.expm1(y_pred_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_transformed, y_pred_transformed)\n",
    "mae = mean_absolute_error(y_test_transformed, y_pred_transformed)\n",
    "r2 = r2_score(y_test_transformed, y_pred_transformed)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R2 Score: {r2}')\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "# Calculate the total time\n",
    "total_time = end_time - start_time\n",
    "# Print the total time\n",
    "print(f\"Total execution time: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f43d4",
   "metadata": {},
   "source": [
    "# Pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9efb7d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved to pipeline_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "pickle_file_path = 'pipeline_model.pkl'\n",
    "\n",
    "# Save the pipeline to a pickle file\n",
    "with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(pipeline, file)\n",
    "\n",
    "print(f'Pipeline saved to {pickle_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3958b6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is AE01-C01E\n",
      "\n",
      " Directory of C:\\Users\\dhami\\Downloads\\GitHub_Capstone_Project\\CTREA-Dynamics\\notebooks\n",
      "\n",
      "31-01-2024  14:08    <DIR>          .\n",
      "30-01-2024  16:53    <DIR>          ..\n",
      "27-01-2024  01:24    <DIR>          .ipynb_checkpoints\n",
      "30-01-2024  02:57    <DIR>          __pycache__\n",
      "27-01-2024  02:54                68 abc.txt\n",
      "25-01-2024  12:55         1,032,504 assessor_output.txt\n",
      "25-01-2024  12:55         1,553,075 Assessor_unique_values.txt\n",
      "25-01-2024  12:54           102,325 assesssor_real_estate_keywords.txt\n",
      "04-01-2024  00:04           289,803 Data_Assessment.ipynb\n",
      "30-01-2024  17:27            67,474 Data_encoding.ipynb\n",
      "30-01-2024  19:59               114 demo.py\n",
      "27-01-2024  02:56             2,768 Deployment_part_1.ipynb\n",
      "31-01-2024  14:08            25,430 Deployment_Steps.ipynb\n",
      "11-01-2024  01:26           854,547 EDA.ipynb\n",
      "25-01-2024  12:55           115,850 final_assessor_output.txt\n",
      "11-01-2024  01:06           169,232 Outliers_Treatment.ipynb\n",
      "31-01-2024  14:08           482,749 pipeline_model.pkl\n",
      "30-01-2024  19:47         1,795,311 Regreession_Model.ipynb\n",
      "30-01-2024  19:59           485,203 regression_pipeline.joblib\n",
      "06-01-2024  01:21         1,172,247 text_keywords.ipynb\n",
      "27-01-2024  02:56    <DIR>          txt_analysis_pending\n",
      "              16 File(s)      8,148,700 bytes\n",
      "               5 Dir(s)  282,153,512,960 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23fba964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deserialisation \n",
    "reloaded_pickle = pickle.load(open('pipeline_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74b1ed2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>List Year</th>\n",
       "      <th>Assessed Value</th>\n",
       "      <th>Sale Amount</th>\n",
       "      <th>Sales Ratio</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Minimum Estimated Occupancy</th>\n",
       "      <th>County</th>\n",
       "      <th>Reason Category</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>168900.0</td>\n",
       "      <td>352000.0</td>\n",
       "      <td>0.4798</td>\n",
       "      <td>Residential</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>Litchfield County</td>\n",
       "      <td>Other</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  List Year  Assessed Value  Sale Amount  Sales Ratio  \\\n",
       "9           9       2020        168900.0     352000.0       0.4798   \n",
       "\n",
       "  Property Type  Street Number  Minimum Estimated Occupancy  \\\n",
       "9   Residential             39                            5   \n",
       "\n",
       "              County Reason Category  year  month  day  \n",
       "9  Litchfield County           Other  2021      8   10  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[9:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b80f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2020, 168900.0, 352000.0, 0.4798, 'Residential', 39, 5,\n",
       "       'Litchfield County', 'Other', 2021, 8, 10], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66e423bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.606732368469238"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'Sale Amount' is the name of the target variable column\n",
    "input_data = [[9, 2020, 168900.0, 352000.0, 0.4798, 'Residential', 39, 5,\n",
    "       'Litchfield County', 'Other', 2021, 8, 10]]\n",
    "\n",
    "sale_amount = input_data[0][3]\n",
    "\n",
    "# Create a DataFrame from the input list\n",
    "input_df = pd.DataFrame(input_data, columns=['Unnamed: 0', 'List Year', 'Assessed Value', 'Sale Amount',\n",
    "       'Sales Ratio', 'Property Type', 'Street Number',\n",
    "       'Minimum Estimated Occupancy', 'County', 'Reason Category', 'year',\n",
    "       'month', 'day'])\n",
    "\n",
    "# Extract the target variable\n",
    "target_variable = input_df['Sale Amount']\n",
    "\n",
    "# Drop the target variable before using the pipeline\n",
    "input_df = input_df.drop(columns=['Sale Amount'])\n",
    "\n",
    "# Use the pipeline for prediction\n",
    "prediction = reloaded_pickle.predict(input_df)\n",
    "\n",
    "prediction = float(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "592365af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298560.84266669047"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inverse of prediction for actual value\n",
    "predict_value = np.expm1(prediction)\n",
    "predict_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed628b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352000.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8f97fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.77138929548529"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa = np.log1p(sale_amount)\n",
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea0af70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53439.15733330953"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#difference between true and preidction\n",
    "error = sale_amount-predict_value\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf10071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16465692701605228"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = sa - prediction\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8dae244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17898857019370834"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db38eb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.886317752317524"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log1p(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecd822",
   "metadata": {},
   "source": [
    "# Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c8ee554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.418462, 9.26592 , 9.5395  , 9.430487, 9.493425, 9.33935 ,\n",
       "       9.785561, 9.785561, 9.166654, 9.20828 ], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib  \n",
    "# For scikit-learn versions < 0.22\n",
    "# For scikit-learn versions >= 0.22, use: from sklearn import joblib\n",
    "\n",
    "# Assuming you have trained the pipeline and stored it in the variable 'pipeline'\n",
    "joblib.dump(pipeline, 'regression_pipeline.joblib')\n",
    "\n",
    "# Load the saved pipeline\n",
    "reloaded_pipeline = joblib.load('regression_pipeline.joblib')\n",
    "\n",
    "# Now, you can use 'reloaded_pipeline' to make predictions\n",
    "y_pred = reloaded_pipeline.predict(X_test)\n",
    "\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "061c0219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12312.627, 10570.528, 13897.   , ..., 22252.613, 14927.105,\n",
       "       34627.477], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f53e610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.70481], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reloaded_pipeline.predict(input_df)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b401aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160219.243"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "170000.0-9780.757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "028722a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16395.286291298802"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(float(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7885b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364213    12.506181\n",
       "685188    11.608245\n",
       "245987    12.802161\n",
       "702718    11.728045\n",
       "40463     12.128117\n",
       "246708    12.468056\n",
       "321763    11.089821\n",
       "333937    12.206078\n",
       "803652    12.255344\n",
       "561435    11.512935\n",
       "Name: Sale Amount, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_transformed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169dc0f",
   "metadata": {},
   "source": [
    "    The pickle is performing better than joblib!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d1890",
   "metadata": {},
   "source": [
    "# Streamlit Application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f0c55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50a52ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting demo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile demo.py\n",
    "import streamlit as st\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "st.header('Machine Learning Regression Model')\n",
    "list_year = st.selectbox('Property Listing Year',\n",
    "                         [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
    "                          2015, 2016, 2017, 2018, 2019, 2020, 2021])\n",
    "sale_recorded_year = st.selectbox('Property Sale Recorded Year',\n",
    "                                  [1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012,\n",
    "                                   2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021])\n",
    "assessed_value = st.number_input('Property Valuation in USD', min_value=0.0, value=10.0,\n",
    "                                 placeholder=\"Type a number...\")\n",
    "sales_ratio = st.number_input('Sales Ratio', min_value=0.00, max_value=5.00, placeholder=\"Type a number...\")\n",
    "property_type = st.selectbox('Property Type', ['Commercial', 'Residential', 'Vacant Land', 'Miscellaneous',\n",
    "                                               'Apartments', 'Industrial', 'Public Utility', 'Condo',\n",
    "                                               'Two Family', 'Single Family', 'Four Family', 'Three Family'])\n",
    "street_number = st.number_input('Street Number ', min_value=0, value=0, placeholder=\"Type a number...\")\n",
    "Minimum_Estimated_Occupancy = st.number_input('Minimum Estimated Occupancy', min_value=1, max_value=16,\n",
    "                                              placeholder=\"Type a number...\")\n",
    "county = st.selectbox('County', ['New Haven County', 'Windham County', 'Hartford County',\n",
    "                                 'Fairfield County', 'Litchfield County', 'Middlesex County',\n",
    "                                 'New London County', 'Tolland County', 'Other'])\n",
    "reason_sale = st.selectbox('Reason for sale', ['Not defined', ' Foreclosure', ' Other', ' Family',\n",
    "                                               ' Change in Property', ' Plottage', ' Use Assessment', ' Tax',\n",
    "                                               ' In Lieu Of Foreclosure', ' Two Towns', ' A Will',\n",
    "                                               ' Portion of Property', ' Part Interest', ' Government Agency',\n",
    "                                               ' Charitable Group', ' Court Order', ' Rehabilitation Deferred',\n",
    "                                               ' Inter Corporation', ' Money and Personal Property',\n",
    "                                               ' Non Buildable Lot', ' Correcting Deed', ' Deed Date',\n",
    "                                               ' CRUMBLING FOUNDATION ASSESSMENT REDUCTION', ' Bankrupcy',\n",
    "                                               ' Auction', ' Love and Affection', ' Personal Property Exchange',\n",
    "                                               ' Zoning', ' Easement', ' Cemetery', ' No Consideration'])\n",
    "\n",
    "button = st.button('Predict Sale Amount')\n",
    "\n",
    "data = {'List Year': [list_year],\n",
    "        'year': [sale_recorded_year],\n",
    "        'Assessed Value': [assessed_value],\n",
    "        'Sales Ratio': [sales_ratio],\n",
    "        'Property Type': [property_type],\n",
    "        'Street Number': [street_number],\n",
    "        'Minimum Estimated Occupancy': [Minimum_Estimated_Occupancy],\n",
    "        'County': [county],\n",
    "        'Reason Category': [reason_sale]}\n",
    "\n",
    "st.markdown('User Inputs')\n",
    "input_data = pd.DataFrame(data)\n",
    "st.dataframe(input_data.T)\n",
    "\n",
    "\n",
    "# Define the drop_columns function\n",
    "def drop_columns(input_data):\n",
    "    return input_data.drop(columns=columns_to_drop)\n",
    "\n",
    "#applying log transformation\n",
    "def apply_log_transformation(input_data):\n",
    "    input_data['Assessed Value'] = np.log1p(input_data['Assessed Value'])\n",
    "    return input_data\n",
    "\n",
    "columns_to_drop = ['Sales Ratio']\n",
    "categorical_features = ['Property Type', 'County', 'Reason Category']\n",
    "\n",
    "# deserialization\n",
    "reloaded_pickle = pickle.load(open(\"C:\\\\Users\\\\dhami\\\\Downloads\\\\Cap_Data\\\\Real_notebooks\\\\pipeline_model.pkl\", 'rb'))\n",
    "# Use the pipeline for prediction\n",
    "prediction = reloaded_pickle.predict(input_data)\n",
    "prediction = float(prediction)\n",
    "#inverse of prediction for actual value\n",
    "predict_value = np.expm1(prediction)\n",
    "st.write(predict_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08c8529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!wget -q -O - ipv4.icanhazip.com\n",
    "#! streamlit run demo.py \n",
    "#& npx localtunnel --port 8501\n",
    "#this works on google colab use ip address on turner for website access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b3674a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the streamlit command in local host in terminal thnen only it works like did in PyCharm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5aaded",
   "metadata": {},
   "source": [
    "# Final Streamlit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04bc728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing regression_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile regression_model.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "st.header('Machine Learning Regression Model')\n",
    "list_year = st.selectbox('Property Listing Year',\n",
    "                         [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n",
    "                          2015, 2016, 2017, 2018, 2019, 2020, 2021])\n",
    "sale_recorded_year = st.selectbox('Property Sale Recorded Year',\n",
    "                                  [1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012,\n",
    "                                   2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021])\n",
    "assessed_value = st.number_input('Property Valuation in USD', min_value=0.0, value=10.0,\n",
    "                                 placeholder=\"Type a number...\")\n",
    "sales_ratio = st.number_input('Sales Ratio', min_value=0.00, max_value=5.00, placeholder=\"Type a number...\")\n",
    "property_type = st.selectbox('Property Type', ['Commercial', 'Residential', 'Vacant Land', 'Miscellaneous',\n",
    "                                               'Apartments', 'Industrial', 'Public Utility', 'Condo',\n",
    "                                               'Two Family', 'Single Family', 'Four Family', 'Three Family'])\n",
    "street_number = st.number_input('Street Number ', min_value=0, value=0, placeholder=\"Type a number...\")\n",
    "Minimum_Estimated_Occupancy = st.number_input('Minimum Estimated Occupancy', min_value=1, max_value=16,\n",
    "                                              placeholder=\"Type a number...\")\n",
    "county = st.selectbox('County', ['New Haven County', 'Windham County', 'Hartford County',\n",
    "                                 'Fairfield County', 'Litchfield County', 'Middlesex County',\n",
    "                                 'New London County', 'Tolland County', 'Other'])\n",
    "reason_sale = st.selectbox('Reason for sale', ['Not defined', ' Foreclosure', ' Other', ' Family',\n",
    "                                               ' Change in Property', ' Plottage', ' Use Assessment', ' Tax',\n",
    "                                               ' In Lieu Of Foreclosure', ' Two Towns', ' A Will',\n",
    "                                               ' Portion of Property', ' Part Interest', ' Government Agency',\n",
    "                                               ' Charitable Group', ' Court Order', ' Rehabilitation Deferred',\n",
    "                                               ' Inter Corporation', ' Money and Personal Property',\n",
    "                                               ' Non Buildable Lot', ' Correcting Deed', ' Deed Date',\n",
    "                                               ' CRUMBLING FOUNDATION ASSESSMENT REDUCTION', ' Bankrupcy',\n",
    "                                               ' Auction', ' Love and Affection', ' Personal Property Exchange',\n",
    "                                               ' Zoning', ' Easement', ' Cemetery', ' No Consideration'])\n",
    "\n",
    "button = st.button('Predict Sale Amount')\n",
    "\n",
    "data = {'List Year': [list_year],\n",
    "        'year': [sale_recorded_year],\n",
    "        'Assessed Value': [assessed_value],\n",
    "        'Sales Ratio': [sales_ratio],\n",
    "        'Property Type': [property_type],\n",
    "        'Street Number': [street_number],\n",
    "        'Minimum Estimated Occupancy': [Minimum_Estimated_Occupancy],\n",
    "        'County': [county],\n",
    "        'Reason Category': [reason_sale]}\n",
    "\n",
    "st.markdown('User Inputs')\n",
    "input_data = pd.DataFrame(data)\n",
    "st.dataframe(input_data.T)\n",
    "\n",
    "if button:\n",
    "    # Define the drop_columns function\n",
    "    def drop_columns(input_data):\n",
    "        return input_data.drop(columns=columns_to_drop)\n",
    "\n",
    "    # applying log transformation\n",
    "    def apply_log_transformation(input_data):\n",
    "        input_data['Assessed Value'] = np.log1p(input_data['Assessed Value'])\n",
    "        return input_data\n",
    "\n",
    "    columns_to_drop = ['Sales Ratio']\n",
    "    categorical_features = ['Property Type', 'County', 'Reason Category']\n",
    "\n",
    "    # deserialization\n",
    "    reloaded_pickle = pickle.load(open(\"C:\\\\Users\\\\dhami\\\\Downloads\\\\Cap_Data\\\\Real_notebooks\\\\pipeline_model.pkl\", 'rb'))\n",
    "    # Use the pipeline for prediction\n",
    "    prediction = reloaded_pickle.predict(input_data)\n",
    "    prediction = float(prediction)\n",
    "    # inverse of prediction for actual value\n",
    "    predict_value = np.expm1(prediction)\n",
    "    st.write('Predicted Sale Amount:', predict_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a8cdfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run regression_model.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
